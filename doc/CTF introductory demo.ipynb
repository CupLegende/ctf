{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import numpy library and create a random matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "n = 4\n",
    "A = np.random.random((n,n))\n",
    "A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create another matrix and multiply the two"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "B = np.random.random((n,n))\n",
    "np.dot(A,B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Cyclops Tensor Framework library and convert numpy matrices to CTF matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import ctf\n",
    "tA = ctf.astensor(A)\n",
    "tB = ctf.astensor(B)\n",
    "ctf.dot(tA,tB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use CTF index-based notation to perform multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tC = ctf.zeros((n,n))\n",
    "tC.i(\"ij\") << tA.i(\"ik\")*tB.i(\"kj\")\n",
    "tC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The particular character `'i','j','k'` don't matter, we can replace them with `'z','?','+'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tC = ctf.zeros((n,n))\n",
    "tC.i(\"z?\") << tA.i(\"z+\")*tB.i(\"+?\")\n",
    "tC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`numpy` actually has similar functionality via `einsum`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.einsum(\"ik,kj->ij\",A,B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ctf.einsum(\"ik,kj->ij\",tA,tB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notation can be used to contract tensor networks, for instance the tensor train (MPS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "k = 2 # rank\n",
    "W = ctf.tsr([k,n,k])\n",
    "V = ctf.tsr([k,n])\n",
    "W.fill_random(-1.0,1.0)\n",
    "V.fill_random(-1.0,1.0)\n",
    "Z = ctf.tsr([n,n,n,n,n,n])\n",
    "Z.i(\"ijklmn\") << V.i(\"ai\")*W.i(\"ajb\")*W.i(\"bkc\")*W.i(\"cld\")*W.i(\"dme\")*V.i(\"en\")\n",
    "print(Z[1:3,0,2,1,0:3,1].reshape((3,2)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using `np.einsum` the contractions look as follows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "V2 = V.to_nparray()\n",
    "W2 = W.to_nparray()\n",
    "Z2 = np.einsum(\"ai,ajb,bkc,cld,dme,en->ijklmn\",V2,W2,W2,W2,W2,V2)\n",
    "print(Z2[1:3,0,2,1,0:3,1].reshape((3,2)))\n",
    "\n",
    "#same possible with CTF\n",
    "Z = ctf.einsum(\"ai,ajb,bkc,cld,dme,en->ijklmn\",V,W,W,W,W,V)\n",
    "print(Z[1:3,0,2,1,0:3,1].reshape((3,2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "To contract together a CP decomposition, we need to use Hadamard products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "U = ctf.tsr([k,n])\n",
    "U.fill_random(-1.0,1.0)\n",
    "\n",
    "Z.set_zero()\n",
    "\n",
    "#note that the `a` index appears in multiple operands\n",
    "Z.i(\"ijklmn\") << U.i(\"ai\")*U.i(\"aj\")*U.i(\"ak\")*U.i(\"al\")*U.i(\"am\")*U.i(\"an\")\n",
    "print(Z[1:3,0,2,1,0:3,1].reshape((3,2)))\n",
    "\n",
    "U2 = U.to_nparray()\n",
    "Z2 = np.einsum(\"ai,aj,ak,al,am,an->ijklmn\",U2,U2,U2,U2,U2,U2)\n",
    "print(Z2[1:3,0,2,1,0:3,1].reshape((3,2)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets test the preformance of the MPS contractions for a different rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import time\n",
    "for k in np.arange(4)*2+2:\n",
    "    t = time.time()\n",
    "    W = ctf.tsr([k,n,k])\n",
    "    V = ctf.tsr([k,n])\n",
    "    W.fill_random(-1.0,1.0)\n",
    "    V.fill_random(-1.0,1.0)\n",
    "    Z = ctf.tsr([n,n,n,n,n,n])\n",
    "    Z.i(\"ijklmn\") << V.i(\"ai\")*W.i(\"ajb\")*W.i(\"bkc\")*W.i(\"cld\")*W.i(\"dme\")*V.i(\"en\")\n",
    "    V2 = V.to_nparray()\n",
    "    W2 = W.to_nparray()\n",
    "    #time CTF, including all initialization and conversions\n",
    "    print(\"ctf   k =\",k,\"took\",time.time()-t,\"seconds.\")\n",
    "    t2 = time.time()\n",
    "    Z2 = np.einsum(\"ai,ajb,bkc,cld,dme,en->ijklmn\",V2,W2,W2,W2,W2,V2)\n",
    "    print(\"numpy k =\",k,\"took\",time.time()-t2,\"seconds.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets create a sparse tensor of total size $4^{12}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Z = ctf.tsr([n,n,n,n,n,n,n,n,n,n,n,n],sp=1)\n",
    "Z.fill_sp_random(-1.,1.,.00001)\n",
    "Z.read_local_nnz()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#create a random vector in a sparse representation\n",
    "v = ctf.tsr([n],sp=1)\n",
    "v.fill_sp_random(0.,1.,1.)\n",
    "\n",
    "#create an order 12 sparse tensor\n",
    "Z = ctf.tsr([n,n,n,n,n,n,n,n,n,n,n,n],sp=1)\n",
    "\n",
    "#fill tensor so that .001% of entries are nonzero\n",
    "Z.fill_sp_random(0.,1.,.00001)\n",
    "\n",
    "#set diagonal to zero\n",
    "Z.i(\"iiiiiiiiiiii\") << 1. \n",
    "\n",
    "str12 = \"1234567890ab\"\n",
    "for i in range(1,12)[::-1]:\n",
    "    #normalize tensor\n",
    "    Z.i(str12[0:i]).scl(1./ctf.sum(Z))\n",
    "    #create tensor with one less dimension\n",
    "    Z_new = ctf.tsr([n for j in range(i)],sp=1)\n",
    "    #contract tensor over its last mode with a vector\n",
    "    Z_new.i(str12[0:i]) << Z.i(str12[0:i+1])*v.i(str12[i])\n",
    "    #replace old tensor with lower-dimensional one\n",
    "    Z = Z_new\n",
    "\n",
    "#read the nonzeros from Z stored on this processor\n",
    "inds, vals = Z.read_local_nnz()\n",
    "print(Z.ndim)\n",
    "print(inds,vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
